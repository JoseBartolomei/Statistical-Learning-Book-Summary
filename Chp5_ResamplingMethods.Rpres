ISL Chapter 5: Resampling Methods
========================================================
author: 
date: 


Chapter 5: Resampling Methods
========================================================
Resampling methods involve repeatedly drawing samples from a training set and refitting a model of interest on each sample in order to obtain additional information about the fitted model.

- Commonly used resampling methods
	- Cross-validation: is used to estimate the **test error** associated with a given statistical learning method in order to evaluate its performance, or to select the appropriate **level of flexibility**.
	- Bootstrap: is most commonly used to provide a **measure of accuracy** of a parameter estimate or of a given statistical learning method.

Resampling Methods
========================================================
- Model assessment: The process of evaluating a model’s performance.
- Model selection:  The process of selecting the proper level of flexibility for a model is known as model selection.
- Test error: is the average error that results from using a statistical learning method to predict the response on a new observation— that is, a measurement that was not used in training the method.
- The use of a particular statistical learning method is warranted if it results in a low test error.

Validation
========================================================

A class of methods that estimate the test error rate by holding out a subset of the training observations from the fitting process, and then applying the statistical learning method to those held out observations.

Cross-Validation
========================================================

The Bootstrap
========================================================

- The bootstrap is a widely applicable and extremely powerful statistical tool that can be used to quantify the uncertainty associated with a given estimator or statistical learning method.
	
- the power of the bootstrap lies in the fact that it can be easily applied to a wide range of statistical learning methods, including some for which a measure of variability is otherwise difficult to obtain and is not automatically output by statistical software.

- In bootstrap, rather than repeatedly obtaining independent data sets from the population, we instead obtain distinct data sets by repeatedly sampling observations from the original data set.

The Bootstrap:
========================================================
- Does not they depend on the unknown parameter $\sigma^2$, the noise variance.

- Does not rely on any of the assumptions of the linear model, and so it is likely giving a more accurate estimate of the standard errors of $\hat\beta_0$ and $\hat\beta_1$

- Rather than repeatedly obtaining independent data sets from the population, we instead obtain distinct data sets by repeatedly sampling observations from the original data set.

Standard Error of the Bootstrap Set
========================================================

$$SE_B(\hat\alpha) = \sqrt{\frac{1}{B-1}\sum^{B}_{r=1}(\hat\alpha^{*r} - \frac{1}{B}\sum^{B}_{r^{'}=1}\hat\alpha^{*r^{'}})}$$

- This serves as an estimate of the standard error of $\hat\alpha$ estimated form the original data set.
